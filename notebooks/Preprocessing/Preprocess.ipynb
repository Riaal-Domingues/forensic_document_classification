{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Preprocessing reference code\n",
    "\n",
    "The first cell below is the basic preprocessing as we call it for final preprocessing.  There is also a py script to perform the same.  This portion below is used for partial processing and as reference code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing experimental data\n",
    "\n",
    "The preprocessing code below is to generate data for preprocessing experiments. Standard preprocessing will remain in place for all emails:\n",
    "1. Remove standard email addresses\n",
    "1. Remove formatting including\n",
    "    1. Visual formatting (e.g. =02, =09, \\n\\n)\n",
    "    1. HTML tags\n",
    "1. Remove stopwords\n",
    "1. Expand contractions\n",
    "1. Lemmatize words (i.e. change them into their root word)\n",
    "1. Removal of single letters and possible double letter words.\n",
    "\n",
    "We are interested in the following experiments in preprocessing:\n",
    "\n",
    "1. The effect of leaving common names in an email.\n",
    "1. Special formats of email addresses that does not conform to external email address notation.\n",
    "1. Detecting single concept words and tying them together in the dictionary.\n",
    "1. Specialised tokenization.\n",
    "1. Filtering out \"Forwaded\" information from email bodies.\n",
    "\n",
    "The code that follows cover incrementally adding the filtering as described for the experiments.  The experiments are performed in relevant notebooks to the specific model under investigation.\n",
    "\n",
    "### Build a file list\n",
    "The first step is to build a file list in memory before commencing processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:56:02.066151Z",
     "iopub.status.busy": "2021-11-10T16:56:02.065482Z",
     "iopub.status.idle": "2021-11-10T16:56:07.561302Z",
     "shell.execute_reply": "2021-11-10T16:56:07.558376Z",
     "shell.execute_reply.started": "2021-11-10T16:56:02.066115Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising the program\n",
      "Importing Spacy\n",
      "Loading encore web\n",
      "Initialisation of eflp complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [00:00, 19693.88it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm   #To display progress bars\n",
    "\n",
    "# Import own defined functions and classes\n",
    "print(\"Initialising the program\")\n",
    "modules_path = os.path.join('..','..','src','modules','')\n",
    "sys.path.append(modules_path)\n",
    "import eflp\n",
    "import importlib\n",
    "importlib.reload(eflp)\n",
    "\n",
    "dir_list = [\"allen-p\",\"arnold-j\",\"arora-h\",\n",
    "            \"badeer-r\",\"bailey-s\",\"bass-e\",\n",
    "            \"baughman-d\",\"beck-s\",\"benson-r\",\n",
    "            \"blair-l\",\"brawner-s\",\"buy-r\",\n",
    "            \"campbell-l\",\"lay-k\",\"skilling-j\"]\n",
    "\n",
    "src_data_root = os.path.join(\"..\",\"..\",\"data\",\"raw\")\n",
    "mail_src = os.path.join(src_data_root,\"maildir\",\"allen-p\")\n",
    "\n",
    "# Load our custom efpl library developed for this project\n",
    "email = eflp.Email_Forensic_Processor()\n",
    "\n",
    "# Define a helper function to construct the file list\n",
    "def build_file_list(src, type = \"\"):\n",
    "    # Initialise the list\n",
    "    src_dst = []\n",
    "    with tqdm() as pbar:\n",
    "        for dir_path, dirs, files in os.walk(src):\n",
    "            src_path = dir_path\n",
    "            for file in files:\n",
    "                #print(file)\n",
    "                if not re.search(r'^\\.',file):      # Ignore hidden files in Unix\n",
    "                    file_src_path = os.path.join(src_path,file)\n",
    "                    file_dst_path = file_src_path.replace(\"/raw/\",\"/processed/\")\n",
    "                    if type == \"experimental\":\n",
    "                        file_dst_path = file_dst_path.replace(\"/maildir/\",\"/experimental_data/\")\n",
    "                    file_dst_path = file_dst_path + \"json\"\n",
    "                    src_dst.append((file_src_path,file_dst_path))\n",
    "                    pbar.update(1)\n",
    "                        #print(\"   \",file_src_path,file_dst_path)\n",
    "    return src_dst\n",
    "\n",
    "\n",
    "# Build a list of the multex.com files\n",
    "def build_file_list_multex(filename, type = \"\"):\n",
    "    # Initialise the list\n",
    "    src_dst = []\n",
    "    file_list = open(src_data_root + \"/\" + filename,\"r\")\n",
    "    file_number = 0\n",
    "    \n",
    "    with tqdm() as pbar:\n",
    "        for file in file_list:\n",
    "            file_number = file_number + 1\n",
    "            src_dst.append((\"../../data/raw/\" + file.strip(),\"../../data/processed/Multex/Multex_\" + str(file_number) + \".json\"))\n",
    "    pbar.update(1)\n",
    "    file_list.close()\n",
    "    return src_dst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "src_dst = build_file_list(mail_src, type = \"experimental\")\n",
    "\n",
    "Multex_list = build_file_list_multex(\"Multex_files.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard full pre-process\n",
    "\n",
    "Run a standard pre-process on the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:22:27.210702Z",
     "iopub.status.busy": "2021-11-10T16:22:27.210229Z",
     "iopub.status.idle": "2021-11-10T16:28:35.884630Z",
     "shell.execute_reply": "2021-11-10T16:28:35.882179Z",
     "shell.execute_reply.started": "2021-11-10T16:22:27.210667Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [06:08,  8.23it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "# Preprocess the emails and store them\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        if os.path.exists(file_pair[1]):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0])\n",
    "            email.saveMail(file_pair[1])\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very basic preprocess\n",
    "\n",
    "The very basic pre-process. This is achieved by a special call to the class to not invoke pre-processing, and then a manual call to the class to invoke a basic pre-process, followed by a call to the class to finalise the basic pre-process. The output filename is modified with a pre-prend string:\n",
    "\n",
    "very_basic_xxx.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:28:35.896103Z",
     "iopub.status.busy": "2021-11-10T16:28:35.894219Z",
     "iopub.status.idle": "2021-11-10T16:36:04.511310Z",
     "shell.execute_reply": "2021-11-10T16:36:04.508065Z",
     "shell.execute_reply.started": "2021-11-10T16:28:35.896001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [07:28,  6.76it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"very_Basic_\"\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"very_basic\")\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic preprocess\n",
    "\n",
    "The basic pre-process.  This is achieved by a special call to the class to not invoke pre-processing, and then a manual call to the class to invoke a basic pre-process, followed by a call to the class to finalise the basic pre-process.  The output filename is modified with a pre-prend string:\n",
    "- basic_xxx.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:37:44.257915Z",
     "iopub.status.busy": "2021-11-10T16:37:44.256993Z",
     "iopub.status.idle": "2021-11-10T16:39:18.759456Z",
     "shell.execute_reply": "2021-11-10T16:39:18.758083Z",
     "shell.execute_reply.started": "2021-11-10T16:37:44.257876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [01:34, 32.11it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Basic_\"\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"basic\")\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering special email addresses\n",
    "\n",
    "The internal email address representation is not standard.  A standard email is of the form:\n",
    "- name@domain.parts\n",
    "\n",
    "However, the javamailer seem to have an internal representation of the form:\n",
    "- name/domain/structure@company\n",
    "\n",
    "The below code performs basic pre-processing, and then additionally filters this special email address format using a specially crafted regular expression.  The destination filename is pre-pended with:\n",
    "- Mailer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:39:18.764132Z",
     "iopub.status.busy": "2021-11-10T16:39:18.763409Z",
     "iopub.status.idle": "2021-11-10T16:41:31.086304Z",
     "shell.execute_reply": "2021-11-10T16:41:31.084309Z",
     "shell.execute_reply.started": "2021-11-10T16:39:18.764085Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [02:12, 22.93it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Mailer_\"\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"mailer\")\n",
    "            #email.remove_patterns(pattern_list = [eflp.EMAIL_ENRON,eflp.TWO_LETTERS])\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering names\n",
    "\n",
    "The name of the mailbox owner may dominate, en therefore should potentially be filtered out.  This is becuase all mails will either address the email box owner, or signed by the email box owner at the end.  Filtering of names may or may not be required, dependend on the final model.\n",
    "\n",
    "The destination filename is pre-pended with:\n",
    "\n",
    "- Name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:41:31.090744Z",
     "iopub.status.busy": "2021-11-10T16:41:31.089866Z",
     "iopub.status.idle": "2021-11-10T16:44:49.424641Z",
     "shell.execute_reply": "2021-11-10T16:44:49.423437Z",
     "shell.execute_reply.started": "2021-11-10T16:41:31.090688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [03:18, 15.30it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Name_\"\n",
    "\n",
    "#Define a regular expression to filer the name.\n",
    "NAME_REGEX = \"[P,p]hillip|[A,a]llen\"\n",
    "NAME = re.compile(NAME_REGEX,flags=re.IGNORECASE)\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"name\")\n",
    "            #email.remove_patterns(pattern_list = [eflp.EMAIL_ENRON,eflp.TWO_LETTERS])\n",
    "            #email.remove_patterns(pattern_list = [NAME,eflp.TWO_LETTERS])\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final full pre-process\n",
    "\n",
    "The final code builds a full pre-process. Refer to the dissertation, or the code in efpl.py in the src folder for the full details.\n",
    "\n",
    "The destination filename is pre-pended with:\n",
    "\n",
    "- Full_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T17:27:13.422036Z",
     "iopub.status.busy": "2021-11-10T17:27:13.419078Z",
     "iopub.status.idle": "2021-11-10T17:40:10.684266Z",
     "shell.execute_reply": "2021-11-10T17:40:10.680624Z",
     "shell.execute_reply.started": "2021-11-10T17:27:13.421931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [12:57,  3.90it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Full_\"\n",
    "\n",
    "#Define a regular expression to filer the name.\n",
    "#NAME_REGEX = \"[P,p]hillip|[A,a]llen\"\n",
    "#NAME = re.compile(NAME_REGEX,flags=re.IGNORECASE)\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"full\")\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final full pre-process for POS\n",
    "\n",
    "For experiment 2, we also compare the Part of Speech (POS) tagging as a way to extract features. The below cell pre-processes the mails, extracting nouns, proper nouns and verbs as features. \n",
    "\n",
    "The destination filename is pre-pended with:\n",
    "\n",
    "- POS_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T17:40:10.694246Z",
     "iopub.status.busy": "2021-11-10T17:40:10.693359Z",
     "iopub.status.idle": "2021-11-10T18:04:24.713110Z",
     "shell.execute_reply": "2021-11-10T18:04:24.712128Z",
     "shell.execute_reply.started": "2021-11-10T17:40:10.694210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [24:13,  2.09it/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"POS_\"\n",
    "\n",
    "#Define a regular expression to filer the name.\n",
    "#NAME_REGEX = \"[P,p]hillip|[A,a]llen\"\n",
    "#NAME = re.compile(NAME_REGEX,flags=re.IGNORECASE)\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"full_pos\")\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for additional tests\n",
    "\n",
    "The code that follows creates subset datasets for additional testing of LDA concepts. The main theory is that by controlling the dictionary with a careful seelction of subsets of data, the LDA algorithm will be better \"tuned\" on specific topics. The full pre-process is run on the subsets in preparation for the LDA algorithm to be applied.\n",
    "\n",
    "### Newsletter\n",
    "The Multex newsletter was identified to be of specific topics. The filenames were extracted by a simple unix command search and saved in Multex_filenames.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-10T16:50:20.596246Z",
     "iopub.status.busy": "2021-11-10T16:50:20.595224Z",
     "iopub.status.idle": "2021-11-10T16:50:20.647887Z",
     "shell.execute_reply": "2021-11-10T16:50:20.644766Z",
     "shell.execute_reply.started": "2021-11-10T16:50:20.596138Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [00:00, 6289.32it/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=(len(Multex_list) - 1)) as pbar:\n",
    "    for file_pair in Multex_list:\n",
    "        # Construct a new output file name.\n",
    "        output_file = file_pair[1]\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            #print(output_file)\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"full\")\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "_________________________________________________________\n",
    "# End Notebook\n",
    "________________\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
