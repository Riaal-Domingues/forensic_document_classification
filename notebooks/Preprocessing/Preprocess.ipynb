{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Preprocessing reference code\n",
    "\n",
    "The first cell below is the basic preprocessing as we call it for final preprocessing.  There is also a py script to perform the same.  This portion below is used for partial processing and as reference code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing experimental data\n",
    "\n",
    "The preprocessing code below is to generate data for preprocessing experiments. Standard preprocessing will remain in place for all emails:\n",
    "1. Remove standard email addresses\n",
    "1. Remove formatting including\n",
    "    1. Visual formatting (e.g. =02, =09, \\n\\n)\n",
    "    1. HTML tags\n",
    "1. Remove stopwords\n",
    "1. Expand contractions\n",
    "1. Lemmatize words (i.e. change them into their root word)\n",
    "1. Removal of single letters and possible double letter words.\n",
    "\n",
    "We are interested in the following experiments in preprocessing:\n",
    "\n",
    "1. The effect of leaving common names in an email.\n",
    "1. Special formats of email addresses that does not conform to external email address notation.\n",
    "1. Detecting single concept words and tying them together in the dictionary.\n",
    "1. Specialised tokenization.\n",
    "1. Filtering out \"Forwaded\" information from email bodies.\n",
    "\n",
    "The code that follows cover incrementally adding the filtering as described for the experiments.  The experiments are performed in relevant notebooks to the specific model under investigation.\n",
    "\n",
    "### Build a file list\n",
    "The first step is to build a file list in memory before commencing processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T16:02:57.684031Z",
     "iopub.status.busy": "2021-08-22T16:02:57.683607Z",
     "iopub.status.idle": "2021-08-22T16:03:06.779949Z",
     "shell.execute_reply": "2021-08-22T16:03:06.775226Z",
     "shell.execute_reply.started": "2021-08-22T16:02:57.683998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising the program\n",
      "Importing Spacy\n",
      "Loading encore web\n",
      "Initialisation of eflp complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [00:00, 18512.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm   #To display progress bars\n",
    "\n",
    "# Import own defined functions and classes\n",
    "print(\"Initialising the program\")\n",
    "modules_path = os.path.join('..','..','src','modules','')\n",
    "sys.path.append(modules_path)\n",
    "import eflp\n",
    "\n",
    "dir_list = [\"allen-p\",\"arnold-j\",\"arora-h\",\n",
    "            \"badeer-r\",\"bailey-s\",\"bass-e\",\n",
    "            \"baughman-d\",\"beck-s\",\"benson-r\",\n",
    "            \"blair-l\",\"brawner-s\",\"buy-r\",\n",
    "            \"campbell-l\",\"lay-k\",\"skilling-j\"]\n",
    "\n",
    "src_data_root = os.path.join(\"..\",\"..\",\"data\",\"raw\")\n",
    "#mail_src = os.path.join(src_data_root,\"maildir\",\"allen-p\",\"_sent_mail\")\n",
    "#mail_src = os.path.join(src_data_root,\"maildir\",\"allen-p\",\"all_documents\")\n",
    "mail_src = os.path.join(src_data_root,\"maildir\",\"allen-p\")\n",
    "\n",
    "\n",
    "email = eflp.Email_Forensic_Processor()\n",
    "\n",
    "# Define a helper function to construct the file list\n",
    "def build_file_list(src, type = \"\"):\n",
    "    # Initialise the list\n",
    "    src_dst = []\n",
    "    with tqdm() as pbar:\n",
    "        for dir_path, dirs, files in os.walk(src):\n",
    "            src_path = dir_path\n",
    "            for file in files:\n",
    "                #print(file)\n",
    "                if not re.search(r'^\\.',file):      # Ignore hidden files in Unix\n",
    "                    file_src_path = os.path.join(src_path,file)\n",
    "                    file_dst_path = file_src_path.replace(\"/raw/\",\"/processed/\")\n",
    "                    if type == \"experimental\":\n",
    "                        file_dst_path = file_dst_path.replace(\"/maildir/\",\"/experimental_data/\")\n",
    "                    file_dst_path = file_dst_path + \"json\"\n",
    "                    src_dst.append((file_src_path,file_dst_path))\n",
    "                    pbar.update(1)\n",
    "                        #print(\"   \",file_src_path,file_dst_path)\n",
    "    return src_dst\n",
    "\n",
    "    \n",
    "src_dst = build_file_list(mail_src, type = \"experimental\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard full pre-process\n",
    "\n",
    "Run a standard pre-process on the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:19:11.851634Z",
     "iopub.status.busy": "2021-08-22T14:19:11.850873Z",
     "iopub.status.idle": "2021-08-22T14:22:03.365299Z",
     "shell.execute_reply": "2021-08-22T14:22:03.363815Z",
     "shell.execute_reply.started": "2021-08-22T14:19:11.851598Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [02:51, 17.69it/s]                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "# Preprocess the emails and store them\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        if os.path.exists(file_pair[1]):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0])\n",
    "            email.saveMail(file_pair[1])\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic preprocess\n",
    "\n",
    "The basic pre-process.  This is achieved by a special call to the class to not invoke pre-processing, and then a manual call to the class to invoke a basic pre-process, followed by a call to the class to finalise the basic pre-process.  The output filename is modified with a pre-prend string:\n",
    "- basic_xxx.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:23:00.174595Z",
     "iopub.status.busy": "2021-08-22T14:23:00.174143Z",
     "iopub.status.idle": "2021-08-22T14:28:25.134108Z",
     "shell.execute_reply": "2021-08-22T14:28:25.132509Z",
     "shell.execute_reply.started": "2021-08-22T14:23:00.174561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [05:24,  9.34it/s]                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Basic_\"\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"basic\")\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering special email addresses\n",
    "\n",
    "The internal email address representation is not standard.  A standard email is of the form:\n",
    "- name@domain.parts\n",
    "\n",
    "However, the javamailer seem to have an internal representation of the form:\n",
    "- name/domain/structure@company\n",
    "\n",
    "The below code performs basic pre-processing, and then additionally filters this special email address format using a specially crafted regular expression.  The filename is pre-pended with:\n",
    "- Mailer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:49:45.170809Z",
     "iopub.status.busy": "2021-08-22T14:49:45.169547Z",
     "iopub.status.idle": "2021-08-22T14:54:22.844116Z",
     "shell.execute_reply": "2021-08-22T14:54:22.842305Z",
     "shell.execute_reply.started": "2021-08-22T14:49:45.170600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [04:37, 10.93it/s]                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Mailer_\"\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"basic\")\n",
    "            email.remove_patterns(pattern_list = [eflp.EMAIL_ENRON,eflp.TWO_LETTERS])\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering names\n",
    "\n",
    "The name of the mailbox owner may dominate, en therefore should potentially be filtered out.  This is becuase all mails will either address the email box owner, or signed by the email box owner at the end.  Filtering of names may or may not be required, dependend on the final model.\n",
    "\n",
    "The file is pre-pended with:\n",
    "\n",
    "- Name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T14:54:22.848471Z",
     "iopub.status.busy": "2021-08-22T14:54:22.847760Z",
     "iopub.status.idle": "2021-08-22T14:59:22.039348Z",
     "shell.execute_reply": "2021-08-22T14:59:22.037647Z",
     "shell.execute_reply.started": "2021-08-22T14:54:22.848423Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [04:59, 10.14it/s]                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Name_\"\n",
    "\n",
    "#Define a regular expression to filer the name.\n",
    "NAME_REGEX = \"[P,p]hillip|[A,a]llen\"\n",
    "NAME = re.compile(NAME_REGEX,flags=re.IGNORECASE)\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"basic\")\n",
    "            email.remove_patterns(pattern_list = [eflp.EMAIL_ENRON,eflp.TWO_LETTERS])\n",
    "            email.remove_patterns(pattern_list = [NAME,eflp.TWO_LETTERS])\n",
    "            email.finalise_preprocess()\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final full pre-process\n",
    "\n",
    "XXXX\n",
    "\n",
    "The file is pre-pended with:\n",
    "\n",
    "- Full_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T16:03:21.880708Z",
     "iopub.status.busy": "2021-08-22T16:03:21.880176Z",
     "iopub.status.idle": "2021-08-22T16:05:31.939700Z",
     "shell.execute_reply": "2021-08-22T16:05:31.937807Z",
     "shell.execute_reply.started": "2021-08-22T16:03:21.880672Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3034it [02:10, 23.33it/s]                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a pre-pend to add to the file name so that experiments can extract the correct pre-processed files. \n",
    "pre_pend = \"Full_\"\n",
    "\n",
    "#Define a regular expression to filer the name.\n",
    "#NAME_REGEX = \"[P,p]hillip|[A,a]llen\"\n",
    "#NAME = re.compile(NAME_REGEX,flags=re.IGNORECASE)\n",
    "\n",
    "with tqdm(total=(len(src_dst) - 1)) as pbar:\n",
    "    for file_pair in src_dst:\n",
    "        # Construct a new output file name.\n",
    "        output_file = os.path.join(os.path.dirname(file_pair[1]),pre_pend + os.path.basename(file_pair[1]))\n",
    "        if os.path.exists(output_file):\n",
    "            #print(\"file exists\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(file_pair[0])\n",
    "            email.initMail(file_pair[0], preProcess = False)\n",
    "            email.preProcess(type=\"full\")\n",
    "            email.saveMail(output_file)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "_________________________________________________________\n",
    "# End Notebook\n",
    "________________\n",
    "\n",
    "\n",
    "## Special experimentation section\n",
    "\n",
    "In the section below we perform general experiments with code.  This will be deleted in the final notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T05:15:10.169776Z",
     "iopub.status.busy": "2021-08-01T05:15:10.169322Z",
     "iopub.status.idle": "2021-08-01T05:15:10.214487Z",
     "shell.execute_reply": "2021-08-01T05:15:10.212612Z",
     "shell.execute_reply.started": "2021-08-01T05:15:10.169743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Forwarded by Phillip K Allen/HOU/ECT on 02/07/2001 \n",
      "07:14 AM ---------------------------\n",
      "\n",
      "\n",
      "Susan J Mara@ENRON\n",
      "02/06/2001 04:12 PM\n",
      "To: Alan Comnes/PDX/ECT@ECT, Angela Schwarz/HOU/EES@EES, Beverly \n",
      "Aden/HOU/EES@EES, Bill Votaw/HOU/EES@EES, Brenda Barreda/HOU/EES@EES, Carol \n",
      "Moffett/HOU/EES@EES, Cathy Corbin/HOU/EES@EES, Chris H Foster/HOU/ECT@ECT, \n",
      "Christina Liscano/HOU/EES@EES, Christopher F Calger/PDX/ECT@ECT, Craig H \n",
      "Sutter/HOU/EES@EES, Dan Leff/HOU/EES@EES, Debora Whitehead/HOU/EES@EES, \n",
      "Dennis Benevides/HOU/EES@EES, Don Black/HOU/EES@EES, Dorothy \n",
      "Youngblood/HOU/ECT@ECT, Douglas Huth/HOU/EES@EES, Edward \n",
      "Sacks/Corp/Enron@ENRON, Eric Melvin/HOU/EES@EES, Erika Dupre/HOU/EES@EES, \n",
      "Evan Hughes/HOU/EES@EES, Fran Deltoro/HOU/EES@EES, Frank W \n",
      "Vickers/HOU/ECT@ECT, Gayle W Muench/HOU/EES@EES, Ginger \n",
      "Dernehl/NA/Enron@ENRON, Gordon Savage/HOU/EES@EES, Harold G \n",
      "Buchanan/HOU/EES@EES, Harry Kingerski/NA/Enron@ENRON, Iris Waser/HOU/EES@EES, \n",
      "James D Steffes/NA/Enron@ENRON, James W Lewis/HOU/EES@EES, James \n",
      "Wright/Western Region/The Bentley Company@Exchange, Jeff Messina/HOU/EES@EES, \n",
      "Jeremy Blachman/HOU/EES@EES, Jess Hewitt/HOU/EES@EES, Joe \n",
      "Hartsoe/Corp/Enron@ENRON, Karen Denne/Corp/Enron@ENRON, Kathy \n",
      "Bass/HOU/EES@EES, Kathy Dodgen/HOU/EES@EES, Ken Gustafson/HOU/EES@EES, Kevin \n",
      "Hughes/HOU/EES@EES, Leasa Lopez/HOU/EES@EES, Leticia Botello/HOU/EES@EES, \n",
      "Mark S Muller/HOU/EES@EES, Marsha Suggs/HOU/EES@EES, Marty Sunde/HOU/EES@EES, \n",
      "Meredith M Eggleston/HOU/EES@EES, Michael Etringer/HOU/ECT@ECT, Michael \n",
      "Mann/HOU/EES@EES, Michelle D Cisneros/HOU/ECT@ECT, mpalmer@enron.com, Neil \n",
      "Bresnan/HOU/EES@EES, Neil Hong/HOU/EES@EES, Paul Kaufman/PDX/ECT@ECT, Paula \n",
      "Warren/HOU/EES@EES, Richard L Zdunkewicz/HOU/EES@EES, Richard \n",
      "Leibert/HOU/EES@EES, Richard Shapiro/NA/Enron@ENRON, Rita \n",
      "Hennessy/NA/Enron@ENRON, Robert Badeer/HOU/ECT@ECT, Rosalinda \n",
      "Tijerina/HOU/EES@EES, Sandra McCubbin/NA/Enron@ENRON, Sarah \n",
      "Novosel/Corp/Enron@ENRON, Scott Gahn/HOU/EES@EES, Scott Stoness/HOU/EES@EES, \n",
      "Sharon Dick/HOU/EES@EES, skean@enron.com, Susan J Mara/NA/Enron@ENRON, Tanya \n",
      "Leslie/HOU/EES@EES, Tasha Lair/HOU/EES@EES, Ted Murphy/HOU/ECT@ECT, Terri \n",
      "Greenlee/NA/Enron@ENRON, Tim Belden/HOU/ECT@ECT, Tony Spruiell/HOU/EES@EES, \n",
      "Vicki Sharp/HOU/EES@EES, Vladimir Gorny/HOU/ECT@ECT, Wanda Curry/HOU/EES@EES, \n",
      "William S Bradford/HOU/ECT@ECT, Jubran Whalan/HOU/EES@EES, triley@enron.com, \n",
      "Richard B Sanders/HOU/ECT@ECT, Robert C \n",
      "Williams/ENRON_DEVELOPMENT@ENRON_DEVELOPMENT, dwatkiss@bracepatt.com, \n",
      "rcarroll@bracepatt.com, Donna Fulton/Corp/Enron@ENRON, gfergus@brobeck.com, \n",
      "Kathryn Corbally/Corp/Enron@ENRON, Bruno Gaillard/EU/Enron@Enron, Linda \n",
      "Robertson/NA/Enron@ENRON, Ren, Lazure/Western Region/The Bentley \n",
      "Company@Exchange, Michael Tribolet/Corp/Enron@Enron, Phillip K \n",
      "Allen/HOU/ECT@ECT, Christian Yoder/HOU/ECT@ECT, jklauber@llgm.com, Tamara \n",
      "Johnson/HOU/EES@EES, Mary Hain/HOU/ECT@ECT, Greg Wolfe/HOU/ECT@ECT, Jeff \n",
      "Dasovich/NA/Enron@Enron, Dirk vanUlden/Western Region/The Bentley \n",
      "Company@Exchange, Steve Walker/SFO/EES@EES, James Wright/Western Region/The \n",
      "Bentley Company@Exchange, Mike D Smith/HOU/EES@EES, Richard \n",
      "Shapiro/NA/Enron@Enron\n",
      "cc:  \n",
      "Subject: Governor Reports Results of 1st RFP -- ONLY 500 MW!!!!\n",
      "\n",
      "Here is a link to the governor's press release.  He is billing it as 5,000 MW \n",
      "of contracts, but then he says that there is only 500 available immediately.  \n",
      "WIth the remainder available from 3 to 10 years.\n",
      "\n",
      "\n",
      "http://www.governor.ca.gov/state/govsite/gov_htmldisplay.jsp?BV_SessionID=@@@@\n",
      "1673762879.0981503886@@@@&BV_EngineID=falkdgkgfmhbemfcfkmchcng.0&sCatTitle=Pre\n",
      "ss+Release&sFilePath=/govsite/press_release/2001_02/20010206_PR01049_longtermc\n",
      "ontracts.html&sTitle=GOVERNOR+DAVIS+ANNOUNCES+LONG+TERM+POWER+SUPPLY&iOID=1325\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------------- Forwarded by Phillip K Allen on 02/07/2001 \n",
      "07:14 AM ---------------------------\n",
      "\n",
      "\n",
      "Susan J Mara\n",
      "02/06/2001 04:12 PM\n",
      "To: Alan Comnes, Angela Schwarz, Beverly \n",
      "Aden, Bill Votaw, Brenda Barreda, Carol \n",
      "Moffett, Cathy Corbin, Chris H Foster, \n",
      "Christina Liscano, Christopher F Calger, Craig H \n",
      "Sutter, Dan Leff, Debora Whitehead, \n",
      "Dennis Benevides, Don Black, Dorothy \n",
      "Youngblood, Douglas Huth, Edward \n",
      "Sacks, Eric Melvin, Erika Dupre, \n",
      "Evan Hughes, Fran Deltoro, Frank W \n",
      "Vickers, Gayle W Muench, Ginger \n",
      "Dernehl, Gordon Savage, Harold G \n",
      "Buchanan, Harry Kingerski, Iris Waser, \n",
      "James D Steffes, James W Lewis, James \n",
      "Wright/Western Region/The Bentley Company@Exchange, Jeff Messina, \n",
      "Jeremy Blachman, Jess Hewitt, Joe \n",
      "Hartsoe, Karen Denne, Kathy \n",
      "Bass, Kathy Dodgen, Ken Gustafson, Kevin \n",
      "Hughes, Leasa Lopez, Leticia Botello, \n",
      "Mark S Muller, Marsha Suggs, Marty Sunde, \n",
      "Meredith M Eggleston, Michael Etringer, Michael \n",
      "Mann, Michelle D Cisneros, , Neil \n",
      "Bresnan, Neil Hong, Paul Kaufman, Paula \n",
      "Warren, Richard L Zdunkewicz, Richard \n",
      "Leibert, Richard Shapiro, Rita \n",
      "Hennessy, Robert Badeer, Rosalinda \n",
      "Tijerina, Sandra McCubbin, Sarah \n",
      "Novosel, Scott Gahn, Scott Stoness, \n",
      "Sharon Dick, , Susan J Mara, Tanya \n",
      "Leslie, Tasha Lair, Ted Murphy, Terri \n",
      "Greenlee, Tim Belden, Tony Spruiell, \n",
      "Vicki Sharp, Vladimir Gorny, Wanda Curry, \n",
      "William S Bradford, Jubran Whalan, , \n",
      "Richard B Sanders, Robert C \n",
      "Williams, , \n",
      ", Donna Fulton, , \n",
      "Kathryn Corbally, Bruno Gaillard, Linda \n",
      "Robertson, Ren, Lazure/Western Region/The Bentley \n",
      "Company@Exchange, Michael Tribolet, Phillip K \n",
      "Allen, Christian Yoder, , Tamara \n",
      "Johnson, Mary Hain, Greg Wolfe, Jeff \n",
      "Dasovich, Dirk vanUlden/Western Region/The Bentley \n",
      "Company@Exchange, Steve Walker, James Wright/Western Region/The \n",
      "Bentley Company@Exchange, Mike D Smith, Richard \n",
      "Shapiro\n",
      "cc:  \n",
      "Subject: Governor Reports Results of 1st RFP -- ONLY 500 MW!!!!\n",
      "\n",
      "Here is a link to the governor's press release.  He is billing it as 5,000 MW \n",
      "of contracts, but then he says that there is only 500 available immediately.  \n",
      "WIth the remainder available from 3 to 10 years.\n",
      "\n",
      "\n",
      "\n",
      "1673762879.0981503886@@@@&BV_EngineID=falkdgkgfmhbemfcfkmchcng.0&sCatTitle=Pre\n",
      "ss+Release&sFilePath=/govsite/press_release/2001_02/20010206_PR01049_longtermc\n",
      "ontracts.html&sTitle=GOVERNOR+DAVIS+ANNOUNCES+LONG+TERM+POWER+SUPPLY&iOID\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "################ Function definitions ###############\n",
    "# A helper function which loads the json email and returns it as a dictionary\n",
    "def loadMail(filename):\n",
    "    with open (filename, \"r\") as inputFile:\n",
    "        return json.load(inputFile)\n",
    "################ End Function definitions ###############\n",
    "\n",
    "email = loadMail(\"../../data/processed/maildir/allen-p/_sent_mail/520.json\")\n",
    "#print(email)\n",
    "\n",
    "FORMATTING_REGEX = r\"=\\n|=\\d+\"\n",
    "\n",
    "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "\n",
    "ENRON_EMAIL_REGEX = r\"/\\w+/\\w+/\\w+@\\w+|/\\w+/\\w+@\\w+|/\\w+@\\w+|/\\w+/Enron Communications@Enron Communication|/HOU/ECT|/NA/Enron|@ENRON\"\n",
    "\n",
    "\n",
    "NAME_REGEX_1 = \"[P,p]hillip\"\n",
    "NAME_REGEX_2 = \"[A,a]llen k\"\n",
    "NAME_REGEX_3 = \"[A,a]llen.\"\n",
    "\n",
    "HTML_REGEX = r\"<.*?>\"\n",
    "CHARACTERS_REGEX = r\"[,_]\"\n",
    "BELONG_REGEX = r\"'s\"\n",
    "TWO_LETTERS_REGEX = r\"\\b[\\w]{1,2}\\b\"\n",
    "\n",
    "#print(FORMATTING_REGEX)\n",
    "FORMATTING = re.compile(FORMATTING_REGEX,flags=re.IGNORECASE)\n",
    "EMAIL = re.compile(EMAIL_REGEX,flags=re.IGNORECASE)\n",
    "EMAIL_ENRON = re.compile(ENRON_EMAIL_REGEX,flags=re.IGNORECASE)\n",
    "HTML = re.compile(HTML_REGEX,flags = re.IGNORECASE)\n",
    "CHARACTERS = re.compile(CHARACTERS_REGEX,flags = re.IGNORECASE)\n",
    "TWO_LETTERS = re.compile(TWO_LETTERS_REGEX,flags = re.IGNORECASE)\n",
    "URL = re.compile(URL_REGEX, flags = re.IGNORECASE)\n",
    "\n",
    "\n",
    "def remove_patterns(text,pattern_list = None, flags = None):\n",
    "    \n",
    "    if pattern_list == None:\n",
    "        return(text)\n",
    "    else:\n",
    "        for pattern in pattern_list:\n",
    "            text = pattern.sub('',text)\n",
    "    return(text)\n",
    "#print(email.keys())\n",
    "print(email['body'])\n",
    "pattern_list = [FORMATTING,EMAIL,URL,EMAIL_ENRON]\n",
    "\n",
    "#sample = \"This is a example of an sentence with two and one letter s s s\"\n",
    "#sample_url = \"http://www.up.za\"\n",
    "#print()\n",
    "#print(TWO_LETTERS.sub('',sample))\n",
    "processed_body = remove_patterns(email['body'],pattern_list = pattern_list)\n",
    "#processed_body = remove_patterns(email.body,pattern_list = pattern_list)\n",
    "print(\"\\n\\n\")\n",
    "print(processed_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T05:15:35.099241Z",
     "iopub.status.busy": "2021-08-01T05:15:35.098777Z",
     "iopub.status.idle": "2021-08-01T05:15:35.153229Z",
     "shell.execute_reply": "2021-08-01T05:15:35.150367Z",
     "shell.execute_reply.started": "2021-08-01T05:15:35.099207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a link to the governor's press release.  He is billing it as 5,000 MW of contracts, but then he says that there is only 500 available immediately.  WIth the remainder available from 3 to 10 years.\n",
      "http://www.governor.ca.gov/state/govsite/gov_htmldisplay.jsp?BV_SessionID=@@@@1673762879.0981503886@@@@&BV_EngineID=falkdgkgfmhbemfcfkmchcng.0&sCatTitle=Press+Release&sFilePath=/govsite/press_release/2001_02/20010206_PR01049_longtermcontracts.html&sTitle=GOVERNOR+DAVIS+ANNOUNCES+LONG+TERM+POWER+SUPPLY&iOID=13250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "################ Function definitions ###############\n",
    "# A helper function which loads the json email and returns it as a dictionary\n",
    "def loadMail(filename):\n",
    "    with open (filename, \"r\") as inputFile:\n",
    "        return json.load(inputFile)\n",
    "################ End Function definitions ###############\n",
    "\n",
    "email = loadMail(\"../../data/processed/maildir/allen-p/_sent_mail/520.json\")\n",
    "#email = loadMail(\"../../data/processed/maildir/allen-p/_sent_mail/2.json\")\n",
    "\n",
    "\n",
    "\n",
    "FORMATTING_REGEX = r\"=\\n|=\\d+\"\n",
    "\n",
    "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "\n",
    "ENRON_EMAIL_REGEX = r\"/\\w+/\\w+/\\w+@\\w+|/\\w+/\\w+@\\w+|/\\w+@\\w+|/\\w+/Enron Communications@Enron Communication|/HOU/\\w+|/NA/Enron|@ENRON\"\n",
    "\n",
    "\n",
    "NAME_REGEX_1 = \"[P,p]hillip\"\n",
    "NAME_REGEX_2 = \"[A,a]llen k\"\n",
    "NAME_REGEX_3 = \"[A,a]llen.\"\n",
    "\n",
    "NAME_REGEX = \"[P,p]hillip|[A,a]llen\"\n",
    "NAME = re.compile(NAME_REGEX, flags = re.IGNORECASE)\n",
    "\n",
    "HTML_REGEX = r\"<.*?>\"\n",
    "CHARACTERS_REGEX = r\"[,_]\"\n",
    "BELONG_REGEX = r\"'s\"\n",
    "TWO_LETTERS_REGEX = r\"\\b[\\w]{1,2}\\b\"\n",
    "\n",
    "#print(FORMATTING_REGEX)\n",
    "FORMATTING = re.compile(FORMATTING_REGEX,flags=re.IGNORECASE)\n",
    "EMAIL = re.compile(EMAIL_REGEX,flags=re.IGNORECASE)\n",
    "EMAIL_ENRON = re.compile(ENRON_EMAIL_REGEX,flags=re.IGNORECASE)\n",
    "HTML = re.compile(HTML_REGEX,flags = re.IGNORECASE)\n",
    "CHARACTERS = re.compile(CHARACTERS_REGEX,flags = re.IGNORECASE)\n",
    "TWO_LETTERS = re.compile(TWO_LETTERS_REGEX,flags = re.IGNORECASE)\n",
    "URL = re.compile(URL_REGEX, flags = re.IGNORECASE)\n",
    "\n",
    "\n",
    "def remove_patterns(text,pattern_list = None, flags = None):\n",
    "    \n",
    "    if pattern_list == None:\n",
    "        return(text)\n",
    "    else:\n",
    "        for pattern in pattern_list:\n",
    "            text = pattern.sub('',text)\n",
    "    return(text)\n",
    "\n",
    "\n",
    "def remove_justify(text):\n",
    "    new_text = \"\"\n",
    "    lines = re.findall(r\".+\\n\", text, flags=0)\n",
    "    for line in lines:\n",
    "        if len(line) == 79:\n",
    "            #print(repr(line))\n",
    "            line = re.sub(r\"\\n\",\"\",line)\n",
    "            #print(repr(line))\n",
    "        elif len(line) == 77:\n",
    "            line = re.sub(r\"=\\n\",\"\",line)\n",
    "        elif len(line) == 75:\n",
    "            line = re.sub(r\"\\n\",\"\",line)\n",
    "\n",
    "        new_text += line\n",
    "        #print(len(line))\n",
    "        #print(repr(line))\n",
    "    return(new_text)\n",
    "\n",
    "def remove_forward(text):\n",
    "    if re.search(r\"(-+ Forwarded by .+Subject:)\",text,flags=re.DOTALL) == None:\n",
    "        #print(re.search(r\"(-+ Forwarded by .+Subject:)\",text))\n",
    "        pass\n",
    "    else:\n",
    "        #print(\"Removing forward\")\n",
    "        text = re.sub(r\"(-+ Forwarded by .+Subject:)\",\"\",text,flags=re.DOTALL)\n",
    "        text = re.sub(r\"^.+\\n\",\"\",text)\n",
    "    return text\n",
    "\n",
    " \n",
    "#print(email['body'])\n",
    "cleaned = remove_justify(email['body'])\n",
    "#print(re.search(r\"-+ Forwarded by .+\",cleaned))\n",
    "#print(cleaned)\n",
    "#print(re.search(r\"(-+ Forwarded by)\",cleaned))\n",
    "cleaned = remove_forward(cleaned)\n",
    "print(cleaned)\n",
    "\n",
    "#print(cleared)\n",
    "\n",
    "                     \n",
    "#print(email['body'])\n",
    "#pattern_list = [FORMATTING,EMAIL,URL,EMAIL_ENRON]\n",
    "#pattern_list = [URL]\n",
    "\n",
    "#url = \"http://www.governor.ca.gov/state/govsite/gov_htmldisplay.jsp?BV_SessionID=@@@@1673762879.0981503886@@@@&BV_EngineID=falkdgkgfmhbemfcfkmchcng.0&sCatTitle=Press+Release&sFilePath=/govsite/press_release/2001_02/20010206_PR01049_longtermcontracts.html&sTitle=GOVERNOR+DAVIS+ANNOUNCES+LONG+TERM+POWER+SUPPLY&iOID=13250\"\n",
    "#print(url)\n",
    "#print(remove_patterns(url, pattern_list = pattern_list))\n",
    "#sample = \"This is a example of an sentence with two and one letter s s s\"\n",
    "#sample_url = \"http://www.up.za\"\n",
    "#print()\n",
    "#print(TWO_LETTERS.sub('',sample))\n",
    "#processed_body = remove_patterns(email['body'],pattern_list = pattern_list)\n",
    "#processed_body = remove_patterns(email.body,pattern_list = pattern_list)\n",
    "#print(\"\\n\\n\")\n",
    "#print(processed_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T05:15:44.182981Z",
     "iopub.status.busy": "2021-08-01T05:15:44.182465Z",
     "iopub.status.idle": "2021-08-01T05:15:44.195530Z",
     "shell.execute_reply": "2021-08-01T05:15:44.193430Z",
     "shell.execute_reply.started": "2021-08-01T05:15:44.182945Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_specification = [\n",
    "    ('NUMBER',   r'\\d+(\\.\\d*)?'),  # Integer or decimal number\n",
    "    ('ASSIGN',   r':='),           # Assignment operator\n",
    "    ('END',      r';'),            # Statement terminator\n",
    "    ('ID',       r'[A-Za-z]+'),    # Identifiers\n",
    "    ('OP',       r'[+\\-*/]'),      # Arithmetic operators\n",
    "    ('NEWLINE',  r'\\n'),           # Line endings\n",
    "    ('SKIP',     r'[ \\t]+'),       # Skip over spaces and tabs\n",
    "    ('MISMATCH', r'.'),            # Any other character\n",
    "]\n",
    "tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T05:15:48.671422Z",
     "iopub.status.busy": "2021-08-01T05:15:48.670278Z",
     "iopub.status.idle": "2021-08-01T05:15:48.687993Z",
     "shell.execute_reply": "2021-08-01T05:15:48.682567Z",
     "shell.execute_reply.started": "2021-08-01T05:15:48.671363Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NUMBER', '\\\\d+(\\\\.\\\\d*)?'), ('ASSIGN', ':='), ('END', ';'), ('ID', '[A-Za-z]+'), ('OP', '[+\\\\-*/]'), ('NEWLINE', '\\\\n'), ('SKIP', '[ \\\\t]+'), ('MISMATCH', '.')]\n",
      "(?P<NUMBER>\\d+(\\.\\d*)?)|(?P<ASSIGN>:=)|(?P<END>;)|(?P<ID>[A-Za-z]+)|(?P<OP>[+\\-*/])|(?P<NEWLINE>\\n)|(?P<SKIP>[ \\t]+)|(?P<MISMATCH>.)\n"
     ]
    }
   ],
   "source": [
    "print(token_specification)\n",
    "print(tok_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
